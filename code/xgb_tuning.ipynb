{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:31:02.590095Z","iopub.status.busy":"2025-01-04T19:31:02.589789Z","iopub.status.idle":"2025-01-04T19:31:04.616081Z","shell.execute_reply":"2025-01-04T19:31:04.615378Z","shell.execute_reply.started":"2025-01-04T19:31:02.590063Z"},"trusted":true},"outputs":[],"source":["# Import necessary dependencies\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import OrdinalEncoder, StandardScaler, PolynomialFeatures, OneHotEncoder\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_absolute_error, r2_score\n","from xgboost import XGBRegressor\n","import xgboost as xgb\n","import seaborn as sns\n","import pickle\n","import optuna"]},{"cell_type":"markdown","metadata":{},"source":["#### Data Loading"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:31:04.617814Z","iopub.status.busy":"2025-01-04T19:31:04.617384Z","iopub.status.idle":"2025-01-04T19:31:41.496532Z","shell.execute_reply":"2025-01-04T19:31:41.495777Z","shell.execute_reply.started":"2025-01-04T19:31:04.617792Z"},"trusted":true},"outputs":[],"source":["# Load target and weights\n","temp_datasets = {}\n","\n","with open('/kaggle/input/rohlik-sales-preprocessed-v1/main_datasets.pkl', 'rb') as f:\n","    temp_datasets = pickle.load(f)\n","\n","X_train, X_val, X_oot, features = temp_datasets['X_train'], temp_datasets['X_val'], temp_datasets['X_oot'], temp_datasets['features']\n","del temp_datasets\n","\n","y_train, y_val, y_oot = X_train.loc[:, 'sales'].copy(), X_val.loc[:, 'sales'].copy(), X_oot.loc[:, 'sales'].copy()\n","train_weights, val_weights, oot_weights = X_train.loc[:, 'weight'].copy(), X_val.loc[:, 'weight'].copy(), X_oot.loc[:, 'weight'].copy()\n","del X_train, X_val, X_oot"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:31:41.498163Z","iopub.status.busy":"2025-01-04T19:31:41.497941Z","iopub.status.idle":"2025-01-04T19:32:15.750701Z","shell.execute_reply":"2025-01-04T19:32:15.749998Z","shell.execute_reply.started":"2025-01-04T19:31:41.498136Z"},"trusted":true},"outputs":[],"source":["# Load features\n","temp_datasets = {}\n","\n","with open('/kaggle/input/rohlik-sales-preprocessed-v1/main_datasets_scaled.pkl', 'rb') as f:\n","    temp_datasets = pickle.load(f)\n","    \n","X_train, X_val, X_oot = temp_datasets['X_train'], temp_datasets['X_val'], temp_datasets['X_oot']\n","del temp_datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:32:15.751777Z","iopub.status.busy":"2025-01-04T19:32:15.751577Z","iopub.status.idle":"2025-01-04T19:32:15.756816Z","shell.execute_reply":"2025-01-04T19:32:15.756045Z","shell.execute_reply.started":"2025-01-04T19:32:15.751760Z"},"trusted":true},"outputs":[],"source":["# Helper function to calculate WMAE\n","def WMAE(y_true: pd.Series | np.ndarray, y_pred: pd.Series | np.ndarray, weights: pd.Series | np.ndarray) -> float:\n","    return np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:32:15.757852Z","iopub.status.busy":"2025-01-04T19:32:15.757580Z","iopub.status.idle":"2025-01-04T19:32:15.771631Z","shell.execute_reply":"2025-01-04T19:32:15.770852Z","shell.execute_reply.started":"2025-01-04T19:32:15.757831Z"},"trusted":true},"outputs":[],"source":["# Helper function to calculate WMAE for training and fine-tuning\n","def wmae(predt: np.ndarray, dtrain: xgb.DMatrix) -> tuple[str, float]:\n","    labels = dtrain.get_label()\n","    weights = dtrain.get_weight()\n","    return 'WMAE', sum(weights * abs(labels - predt)) / sum(weights)"]},{"cell_type":"markdown","metadata":{},"source":["#### XGBRegressor fine-tuning"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T13:46:35.270526Z","iopub.status.busy":"2025-01-04T13:46:35.270210Z","iopub.status.idle":"2025-01-04T13:46:35.290172Z","shell.execute_reply":"2025-01-04T13:46:35.289358Z","shell.execute_reply.started":"2025-01-04T13:46:35.270496Z"},"trusted":true},"outputs":[],"source":["model = XGBRegressor()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T13:46:35.291344Z","iopub.status.busy":"2025-01-04T13:46:35.291037Z","iopub.status.idle":"2025-01-04T13:47:54.729653Z","shell.execute_reply":"2025-01-04T13:47:54.728846Z","shell.execute_reply.started":"2025-01-04T13:46:35.291314Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=None, device=None, early_stopping_rounds=None,\n","             enable_categorical=False, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=None, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=None, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=None, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=None, device=None, early_stopping_rounds=None,\n","             enable_categorical=False, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=None, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=None, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=None, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"],"text/plain":["XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=None, device=None, early_stopping_rounds=None,\n","             enable_categorical=False, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=None, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=None, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=None, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model = XGBRegressor().fit(X_train, y_train)\n","model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:39:15.415220Z","iopub.status.busy":"2025-01-04T19:39:15.414927Z","iopub.status.idle":"2025-01-04T19:39:37.286495Z","shell.execute_reply":"2025-01-04T19:39:37.285740Z","shell.execute_reply.started":"2025-01-04T19:39:15.415198Z"},"trusted":true},"outputs":[],"source":["# Transform data into DMatrices\n","DM_train = xgb.DMatrix(data=X_train, label=y_train, weight=train_weights)\n","DM_val = xgb.DMatrix(data=X_val, label=y_val, weight=val_weights)\n","DM_oot = xgb.DMatrix(data=X_oot, label=y_oot, weight=oot_weights)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["del DM_val, DM_oot"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T14:15:08.014577Z","iopub.status.busy":"2025-01-04T14:15:08.014190Z","iopub.status.idle":"2025-01-04T14:15:08.910382Z","shell.execute_reply":"2025-01-04T14:15:08.909338Z","shell.execute_reply.started":"2025-01-04T14:15:08.014540Z"},"trusted":true},"outputs":[],"source":["del X_train, X_val, X_oot"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T14:35:01.184497Z","iopub.status.busy":"2025-01-04T14:35:01.184160Z","iopub.status.idle":"2025-01-04T14:35:01.189891Z","shell.execute_reply":"2025-01-04T14:35:01.189001Z","shell.execute_reply.started":"2025-01-04T14:35:01.184472Z"},"trusted":true},"outputs":[],"source":["# Define objective for Bayesian optimization\n","def objective(trial):\n","    params = {\n","        'tree_method': 'hist',\n","        'device': 'cuda',\n","        'objective': 'reg:squarederror',\n","        #'eval_metric': wmae,\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n","        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n","        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n","        'gamma': trial.suggest_float('gamma', 0, 0.5),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n","    }\n","\n","    model = xgb.train(\n","        params,\n","        DM_train,\n","        num_boost_round=1000,\n","        evals=[(DM_val, 'val')],\n","        early_stopping_rounds=50,\n","        feval=wmae,\n","        verbose_eval=False\n","    )\n","\n","    predictions = model.predict(DM_val)\n","\n","    return mean_absolute_error(y_val, predictions, sample_weight=val_weights)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T14:35:03.914757Z","iopub.status.busy":"2025-01-04T14:35:03.914449Z","iopub.status.idle":"2025-01-04T18:51:31.598655Z","shell.execute_reply":"2025-01-04T18:51:31.597715Z","shell.execute_reply.started":"2025-01-04T14:35:03.914735Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-01-04 14:35:03,915] A new study created in memory with name: no-name-25181468-6b11-4de1-94c2-f0271d0bf756\n","[I 2025-01-04 14:40:16,741] Trial 0 finished with value: 21.042291548329416 and parameters: {'max_depth': 9, 'learning_rate': 0.10030640756936818, 'subsample': 0.9533098393777967, 'colsample_bytree': 0.6662756192658198, 'min_child_weight': 6, 'gamma': 0.17016039597364047, 'reg_alpha': 0.6319653168494699, 'reg_lambda': 0.9816708607986481}. Best is trial 0 with value: 21.042291548329416.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 14:45:27,688] Trial 1 finished with value: 28.028851061848275 and parameters: {'max_depth': 9, 'learning_rate': 0.03839191107145719, 'subsample': 0.8514898152345085, 'colsample_bytree': 0.6772352938725226, 'min_child_weight': 9, 'gamma': 0.04110176501736956, 'reg_alpha': 0.06747288206939617, 'reg_lambda': 0.06722734753094672}. Best is trial 0 with value: 21.042291548329416.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 14:50:26,436] Trial 2 finished with value: 21.905485325663648 and parameters: {'max_depth': 7, 'learning_rate': 0.1995467035581241, 'subsample': 0.6616938352808983, 'colsample_bytree': 0.9777956078028713, 'min_child_weight': 9, 'gamma': 0.14471754328416242, 'reg_alpha': 0.059001156731786186, 'reg_lambda': 0.5556201881138136}. Best is trial 0 with value: 21.042291548329416.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 14:55:46,450] Trial 3 finished with value: 20.680191362799373 and parameters: {'max_depth': 10, 'learning_rate': 0.07314410176705975, 'subsample': 0.9478205448900545, 'colsample_bytree': 0.8193489994052888, 'min_child_weight': 2, 'gamma': 0.1691065888692997, 'reg_alpha': 0.19318274896139942, 'reg_lambda': 0.19568770675076474}. Best is trial 3 with value: 20.680191362799373.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:00:46,499] Trial 4 finished with value: 21.751857626057664 and parameters: {'max_depth': 7, 'learning_rate': 0.2223431800512946, 'subsample': 0.7200837470273556, 'colsample_bytree': 0.664218059089228, 'min_child_weight': 2, 'gamma': 0.31299499434780725, 'reg_alpha': 0.8472031629277612, 'reg_lambda': 0.07576537575386144}. Best is trial 3 with value: 20.680191362799373.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:06:03,695] Trial 5 finished with value: 20.540800533337787 and parameters: {'max_depth': 10, 'learning_rate': 0.08193124481202863, 'subsample': 0.6241304735390143, 'colsample_bytree': 0.7353355216315283, 'min_child_weight': 8, 'gamma': 0.23565316077744985, 'reg_alpha': 0.4500184764407458, 'reg_lambda': 0.7558096008051707}. Best is trial 5 with value: 20.540800533337787.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:10:51,024] Trial 6 finished with value: 39.844837652582875 and parameters: {'max_depth': 4, 'learning_rate': 0.06936222500882983, 'subsample': 0.7208968299162208, 'colsample_bytree': 0.6024680323153918, 'min_child_weight': 5, 'gamma': 0.4573000736678334, 'reg_alpha': 0.607243224394835, 'reg_lambda': 0.5893167680221043}. Best is trial 5 with value: 20.540800533337787.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:16:06,603] Trial 7 finished with value: 18.510525025117165 and parameters: {'max_depth': 10, 'learning_rate': 0.16850286970524314, 'subsample': 0.6795301615566959, 'colsample_bytree': 0.8965275804533939, 'min_child_weight': 10, 'gamma': 0.21652665569093332, 'reg_alpha': 0.9448967613592862, 'reg_lambda': 0.8290224529624095}. Best is trial 7 with value: 18.510525025117165.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:20:55,897] Trial 8 finished with value: 32.286180098733574 and parameters: {'max_depth': 4, 'learning_rate': 0.21549044912942233, 'subsample': 0.6460906204790007, 'colsample_bytree': 0.6075222121791509, 'min_child_weight': 7, 'gamma': 0.22830630407928332, 'reg_alpha': 0.6551406332896564, 'reg_lambda': 0.5175282746678653}. Best is trial 7 with value: 18.510525025117165.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:25:45,708] Trial 9 finished with value: 31.534714024345938 and parameters: {'max_depth': 4, 'learning_rate': 0.22146083524968088, 'subsample': 0.9637046586007043, 'colsample_bytree': 0.6520857954651373, 'min_child_weight': 2, 'gamma': 0.13104493719900673, 'reg_alpha': 0.9835887269877928, 'reg_lambda': 0.16691738678516266}. Best is trial 7 with value: 18.510525025117165.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:30:39,294] Trial 10 finished with value: 22.591019492189506 and parameters: {'max_depth': 6, 'learning_rate': 0.290516809360759, 'subsample': 0.8147604831900028, 'colsample_bytree': 0.9154012414919797, 'min_child_weight': 10, 'gamma': 0.36650627769297595, 'reg_alpha': 0.3590274378478726, 'reg_lambda': 0.9771561968594512}. Best is trial 7 with value: 18.510525025117165.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:35:52,826] Trial 11 finished with value: 19.065589284058614 and parameters: {'max_depth': 10, 'learning_rate': 0.12839718492716531, 'subsample': 0.6019740231926289, 'colsample_bytree': 0.7878029066629173, 'min_child_weight': 8, 'gamma': 0.28174845938473225, 'reg_alpha': 0.38320054726089825, 'reg_lambda': 0.7648682172859453}. Best is trial 7 with value: 18.510525025117165.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:40:56,888] Trial 12 finished with value: 21.469108229848818 and parameters: {'max_depth': 8, 'learning_rate': 0.14077156832532414, 'subsample': 0.6049758565180531, 'colsample_bytree': 0.8338824348756205, 'min_child_weight': 10, 'gamma': 0.335860540842022, 'reg_alpha': 0.30564622729913227, 'reg_lambda': 0.7847411013448798}. Best is trial 7 with value: 18.510525025117165.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:46:11,026] Trial 13 finished with value: 18.377604273937035 and parameters: {'max_depth': 10, 'learning_rate': 0.15155998868866105, 'subsample': 0.7225729791206484, 'colsample_bytree': 0.8835803137605434, 'min_child_weight': 4, 'gamma': 0.4154390771888745, 'reg_alpha': 0.7768590577911406, 'reg_lambda': 0.7612410373543772}. Best is trial 13 with value: 18.377604273937035.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:51:11,749] Trial 14 finished with value: 20.419416225953203 and parameters: {'max_depth': 8, 'learning_rate': 0.16964018121355762, 'subsample': 0.7304617544164004, 'colsample_bytree': 0.888489822814624, 'min_child_weight': 4, 'gamma': 0.45960758494534293, 'reg_alpha': 0.8623171161461947, 'reg_lambda': 0.3784488147548747}. Best is trial 13 with value: 18.377604273937035.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 15:56:06,605] Trial 15 finished with value: 22.82691258824072 and parameters: {'max_depth': 6, 'learning_rate': 0.27145410337426157, 'subsample': 0.7560219860157636, 'colsample_bytree': 0.9729487688650911, 'min_child_weight': 4, 'gamma': 0.3943200515397226, 'reg_alpha': 0.783191596479804, 'reg_lambda': 0.8666518378930907}. Best is trial 13 with value: 18.377604273937035.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:01:14,928] Trial 16 finished with value: 19.184143009066084 and parameters: {'max_depth': 9, 'learning_rate': 0.1658681888576285, 'subsample': 0.6829682702325539, 'colsample_bytree': 0.8949453214493966, 'min_child_weight': 4, 'gamma': 0.03924980947128559, 'reg_alpha': 0.9735103691724798, 'reg_lambda': 0.6802054861372868}. Best is trial 13 with value: 18.377604273937035.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:06:15,808] Trial 17 finished with value: 21.609507479154047 and parameters: {'max_depth': 8, 'learning_rate': 0.11990245826873186, 'subsample': 0.7898443726122029, 'colsample_bytree': 0.8590515150873587, 'min_child_weight': 1, 'gamma': 0.4062097633757278, 'reg_alpha': 0.7244810720356665, 'reg_lambda': 0.43276957720673903}. Best is trial 13 with value: 18.377604273937035.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:11:01,692] Trial 18 finished with value: 38.2338064968477 and parameters: {'max_depth': 3, 'learning_rate': 0.17981434330709062, 'subsample': 0.8683312665218014, 'colsample_bytree': 0.9398079656510275, 'min_child_weight': 6, 'gamma': 0.4970538365378567, 'reg_alpha': 0.5370325784838902, 'reg_lambda': 0.8719228610205181}. Best is trial 13 with value: 18.377604273937035.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:16:19,882] Trial 19 finished with value: 18.26105709821867 and parameters: {'max_depth': 10, 'learning_rate': 0.24955890666198083, 'subsample': 0.6879350869670763, 'colsample_bytree': 0.783139064688744, 'min_child_weight': 5, 'gamma': 0.08125604163440087, 'reg_alpha': 0.9179429454380386, 'reg_lambda': 0.6984053942696045}. Best is trial 19 with value: 18.26105709821867.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:21:27,337] Trial 20 finished with value: 18.604607863205402 and parameters: {'max_depth': 9, 'learning_rate': 0.2557478341729613, 'subsample': 0.7826026899473416, 'colsample_bytree': 0.7715753541367952, 'min_child_weight': 5, 'gamma': 0.08637526438703237, 'reg_alpha': 0.7416836243174734, 'reg_lambda': 0.6521800793959163}. Best is trial 19 with value: 18.26105709821867.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:26:45,482] Trial 21 finished with value: 18.24725719817203 and parameters: {'max_depth': 10, 'learning_rate': 0.2510287084493607, 'subsample': 0.6876404878473446, 'colsample_bytree': 0.744580402354601, 'min_child_weight': 3, 'gamma': 0.0015254135337360308, 'reg_alpha': 0.8857162643880653, 'reg_lambda': 0.8239192587596702}. Best is trial 21 with value: 18.24725719817203.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:32:02,867] Trial 22 finished with value: 18.21632444557337 and parameters: {'max_depth': 10, 'learning_rate': 0.24604570436672918, 'subsample': 0.6946924285357591, 'colsample_bytree': 0.7331177179561044, 'min_child_weight': 3, 'gamma': 0.005035243964701811, 'reg_alpha': 0.8636736086540819, 'reg_lambda': 0.6555176082263862}. Best is trial 22 with value: 18.21632444557337.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:37:10,487] Trial 23 finished with value: 18.961670365634532 and parameters: {'max_depth': 9, 'learning_rate': 0.2511011889918418, 'subsample': 0.6821925947137041, 'colsample_bytree': 0.7289869012252221, 'min_child_weight': 3, 'gamma': 0.00046662712625925506, 'reg_alpha': 0.8849541381032741, 'reg_lambda': 0.658342790076112}. Best is trial 22 with value: 18.21632444557337.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:42:11,984] Trial 24 finished with value: 19.52418368626916 and parameters: {'max_depth': 8, 'learning_rate': 0.28911595011622127, 'subsample': 0.7536637252626628, 'colsample_bytree': 0.7413638574940434, 'min_child_weight': 3, 'gamma': 0.0015697487622591405, 'reg_alpha': 0.8917526403867095, 'reg_lambda': 0.426710589285102}. Best is trial 22 with value: 18.21632444557337.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:47:26,209] Trial 25 finished with value: 18.31401880020139 and parameters: {'max_depth': 10, 'learning_rate': 0.2442310388435205, 'subsample': 0.697387160476537, 'colsample_bytree': 0.7065064700808907, 'min_child_weight': 3, 'gamma': 0.07803849684645996, 'reg_alpha': 0.8387514040655868, 'reg_lambda': 0.9102458811671528}. Best is trial 22 with value: 18.21632444557337.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:52:32,920] Trial 26 finished with value: 19.2329907637673 and parameters: {'max_depth': 9, 'learning_rate': 0.1936196275599088, 'subsample': 0.6391226325778301, 'colsample_bytree': 0.7557439111762206, 'min_child_weight': 1, 'gamma': 0.08865435734225446, 'reg_alpha': 0.9987304864977266, 'reg_lambda': 0.6879539015353122}. Best is trial 22 with value: 18.21632444557337.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 16:57:22,909] Trial 27 finished with value: 25.73252803342433 and parameters: {'max_depth': 5, 'learning_rate': 0.26574704273400956, 'subsample': 0.8269286034651923, 'colsample_bytree': 0.7981429159272663, 'min_child_weight': 5, 'gamma': 0.051689684186363716, 'reg_alpha': 0.7099846002991612, 'reg_lambda': 0.6118185260216259}. Best is trial 22 with value: 18.21632444557337.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:02:39,314] Trial 28 finished with value: 18.127084538674733 and parameters: {'max_depth': 10, 'learning_rate': 0.2365266810352819, 'subsample': 0.7617842710446067, 'colsample_bytree': 0.7029046742432996, 'min_child_weight': 3, 'gamma': 0.11606881134350354, 'reg_alpha': 0.5555068859178297, 'reg_lambda': 0.3352035886916059}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:07:46,787] Trial 29 finished with value: 18.73320799608998 and parameters: {'max_depth': 9, 'learning_rate': 0.298675034451763, 'subsample': 0.7550242908292778, 'colsample_bytree': 0.6973492705867999, 'min_child_weight': 3, 'gamma': 0.11380622246269594, 'reg_alpha': 0.5514185886426829, 'reg_lambda': 0.31123744604899223}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:12:46,111] Trial 30 finished with value: 21.329081495686925 and parameters: {'max_depth': 7, 'learning_rate': 0.23498660031379456, 'subsample': 0.8992319267322617, 'colsample_bytree': 0.6394793715985374, 'min_child_weight': 2, 'gamma': 0.19060049002765925, 'reg_alpha': 0.6376082813581634, 'reg_lambda': 0.3082017204316327}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:18:02,920] Trial 31 finished with value: 18.345537775719915 and parameters: {'max_depth': 10, 'learning_rate': 0.2692959481675877, 'subsample': 0.7046808404251214, 'colsample_bytree': 0.7016359003575254, 'min_child_weight': 6, 'gamma': 0.020568788459411236, 'reg_alpha': 0.9297173710621036, 'reg_lambda': 0.9902421593938071}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:23:19,984] Trial 32 finished with value: 18.301947328624937 and parameters: {'max_depth': 10, 'learning_rate': 0.20606951777332502, 'subsample': 0.658806998480963, 'colsample_bytree': 0.7696716611874139, 'min_child_weight': 3, 'gamma': 0.06547329218747938, 'reg_alpha': 0.80495658098786, 'reg_lambda': 0.47439519291569837}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:28:28,864] Trial 33 finished with value: 18.81791828701263 and parameters: {'max_depth': 9, 'learning_rate': 0.23031230872245045, 'subsample': 0.7710663855054465, 'colsample_bytree': 0.7168374208872077, 'min_child_weight': 4, 'gamma': 0.11535021825185379, 'reg_alpha': 0.1785704311596471, 'reg_lambda': 0.5268162431275034}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:33:46,797] Trial 34 finished with value: 30.68698112962644 and parameters: {'max_depth': 10, 'learning_rate': 0.019125373174257554, 'subsample': 0.743105929577538, 'colsample_bytree': 0.824550534495273, 'min_child_weight': 1, 'gamma': 0.03583109197934049, 'reg_alpha': 0.6815249413232729, 'reg_lambda': 0.31722808947857717}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:38:49,883] Trial 35 finished with value: 20.559628261782755 and parameters: {'max_depth': 8, 'learning_rate': 0.1912389961019879, 'subsample': 0.6713564530673242, 'colsample_bytree': 0.6721156752230955, 'min_child_weight': 2, 'gamma': 0.15705179255248197, 'reg_alpha': 0.9174312586313835, 'reg_lambda': 0.7066872806987778}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:43:58,409] Trial 36 finished with value: 19.037994074111147 and parameters: {'max_depth': 9, 'learning_rate': 0.2738409330323706, 'subsample': 0.6930460793377335, 'colsample_bytree': 0.687482350052294, 'min_child_weight': 6, 'gamma': 0.10175636168166423, 'reg_alpha': 0.008052671313900861, 'reg_lambda': 0.5992024910149396}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:49:13,776] Trial 37 finished with value: 18.44535467108963 and parameters: {'max_depth': 10, 'learning_rate': 0.23752966478656878, 'subsample': 0.634537552124687, 'colsample_bytree': 0.7522890146806206, 'min_child_weight': 5, 'gamma': 0.1880378173716853, 'reg_alpha': 0.58939265958409, 'reg_lambda': 0.9270872984027813}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:54:22,459] Trial 38 finished with value: 18.54376631476993 and parameters: {'max_depth': 9, 'learning_rate': 0.20840172111810842, 'subsample': 0.9974246274765185, 'colsample_bytree': 0.7859715347017404, 'min_child_weight': 7, 'gamma': 0.023033074925659425, 'reg_alpha': 0.4537867270778632, 'reg_lambda': 0.2270036728748292}. Best is trial 28 with value: 18.127084538674733.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 17:59:38,241] Trial 39 finished with value: 18.06917898688031 and parameters: {'max_depth': 10, 'learning_rate': 0.2537400839413723, 'subsample': 0.7076939162504635, 'colsample_bytree': 0.808729670358781, 'min_child_weight': 3, 'gamma': 0.06288940827561051, 'reg_alpha': 0.222048017933006, 'reg_lambda': 0.81477222217481}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:04:47,317] Trial 40 finished with value: 18.96356375530705 and parameters: {'max_depth': 9, 'learning_rate': 0.28481024555963735, 'subsample': 0.7097966843271698, 'colsample_bytree': 0.6396648117892599, 'min_child_weight': 2, 'gamma': 0.04934721220401883, 'reg_alpha': 0.22887215773067499, 'reg_lambda': 0.7963507978934348}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:10:04,154] Trial 41 finished with value: 18.2097374590784 and parameters: {'max_depth': 10, 'learning_rate': 0.2509387013236093, 'subsample': 0.662009651687358, 'colsample_bytree': 0.8042618683736914, 'min_child_weight': 3, 'gamma': 0.14110555181170398, 'reg_alpha': 0.13129415576182568, 'reg_lambda': 0.8306249542937005}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:15:21,465] Trial 42 finished with value: 18.192765997022565 and parameters: {'max_depth': 10, 'learning_rate': 0.22594440440444616, 'subsample': 0.6591310161673818, 'colsample_bytree': 0.8126297224233213, 'min_child_weight': 3, 'gamma': 0.13767413986689783, 'reg_alpha': 0.15350665586635678, 'reg_lambda': 0.8455986794129015}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:20:38,651] Trial 43 finished with value: 18.070394148670015 and parameters: {'max_depth': 10, 'learning_rate': 0.21970090572502277, 'subsample': 0.6604767630779758, 'colsample_bytree': 0.8538374553230336, 'min_child_weight': 2, 'gamma': 0.14183190441631865, 'reg_alpha': 0.11565308184163159, 'reg_lambda': 0.9101362369786492}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:25:56,059] Trial 44 finished with value: 18.17413341663576 and parameters: {'max_depth': 10, 'learning_rate': 0.22185755901467655, 'subsample': 0.6531916432144682, 'colsample_bytree': 0.8432754727890834, 'min_child_weight': 2, 'gamma': 0.13835599211325572, 'reg_alpha': 0.09830055596730769, 'reg_lambda': 0.939037057904486}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:31:04,875] Trial 45 finished with value: 18.958117312912588 and parameters: {'max_depth': 9, 'learning_rate': 0.22487565563501055, 'subsample': 0.6203376994748409, 'colsample_bytree': 0.8441744504581298, 'min_child_weight': 1, 'gamma': 0.17927670975882798, 'reg_alpha': 0.0889420660978664, 'reg_lambda': 0.9258189343947607}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:36:22,259] Trial 46 finished with value: 18.15620871455566 and parameters: {'max_depth': 10, 'learning_rate': 0.21578692603356037, 'subsample': 0.6505892978044737, 'colsample_bytree': 0.8611013830807986, 'min_child_weight': 2, 'gamma': 0.26434740126908296, 'reg_alpha': 0.26459870116553086, 'reg_lambda': 0.9292485721864685}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:41:38,309] Trial 47 finished with value: 18.215885185953603 and parameters: {'max_depth': 10, 'learning_rate': 0.18407613288768176, 'subsample': 0.644334048067386, 'colsample_bytree': 0.8685064817632322, 'min_child_weight': 2, 'gamma': 0.2775459261562029, 'reg_alpha': 0.24425990750023685, 'reg_lambda': 0.9503823404237203}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:46:40,913] Trial 48 finished with value: 20.122392857647363 and parameters: {'max_depth': 8, 'learning_rate': 0.21320379248079316, 'subsample': 0.6222899296748793, 'colsample_bytree': 0.8558093813121478, 'min_child_weight': 2, 'gamma': 0.22075531619638644, 'reg_alpha': 0.28000805927859596, 'reg_lambda': 0.035564509464217964}. Best is trial 39 with value: 18.06917898688031.\n","/usr/local/lib/python3.10/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n","  warnings.warn(\n","[I 2025-01-04 18:51:31,594] Trial 49 finished with value: 27.150471338330327 and parameters: {'max_depth': 5, 'learning_rate': 0.2013311227582505, 'subsample': 0.7299147965924855, 'colsample_bytree': 0.9178381347114316, 'min_child_weight': 1, 'gamma': 0.25114098608351487, 'reg_alpha': 0.006074589386585408, 'reg_lambda': 0.8948126393192053}. Best is trial 39 with value: 18.06917898688031.\n"]}],"source":["study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=50)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:09:33.930819Z","iopub.status.busy":"2025-01-04T19:09:33.930407Z","iopub.status.idle":"2025-01-04T19:09:33.936223Z","shell.execute_reply":"2025-01-04T19:09:33.935269Z","shell.execute_reply.started":"2025-01-04T19:09:33.930790Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'max_depth': 10, 'learning_rate': 0.2537400839413723, 'subsample': 0.7076939162504635, 'colsample_bytree': 0.808729670358781, 'min_child_weight': 3, 'gamma': 0.06288940827561051, 'reg_alpha': 0.222048017933006, 'reg_lambda': 0.81477222217481}\n"]}],"source":["# Take a look at best parameters\n","best_params = study.best_params\n","print(\"Best hyperparameters:\", best_params)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2025-01-04T19:56:26.912592Z","iopub.status.busy":"2025-01-04T19:56:26.912238Z","iopub.status.idle":"2025-01-04T19:56:27.752246Z","shell.execute_reply":"2025-01-04T19:56:27.751347Z","shell.execute_reply.started":"2025-01-04T19:56:26.912564Z"},"trusted":true},"outputs":[],"source":["# Save best parameters\n","best_parameters = {\n","    'tree_method': 'hist',\n","    'device': 'cuda',\n","    'objective': 'reg:squarederror',\n","    'max_depth': 10,\n","    'learning_rate': 0.2537400839413723,\n","    'subsample': 0.7076939162504635,\n","    'colsample_bytree': 0.808729670358781,\n","    'min_child_weight': 3,\n","    'gamma': 0.06288940827561051,\n","    'reg_alpha': 0.222048017933006,\n","    'reg_lambda': 0.81477222217481\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train model with best parameters\n","model = xgb.train(\n","        best_parameters,\n","        DM_train,\n","        num_boost_round=1000,\n","        evals=[(DM_val, 'val')],\n","        early_stopping_rounds=50,\n","        custom_metric=wmae,\n","        verbose_eval=False\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('/kaggle/input/rohlik-sales-preprocessed-v1/test_dataset_scaled.pkl', 'rb') as f:\n","    X_test = xgb.DMatrix(data=pickle.load(f)['X_test'])\n","\n","with open('/kaggle/input/rohlik-sales-preprocessed-v1/test_dataset.pkl', 'rb') as f:\n","    X_test_id = pickle.load(f)['X_test']\n","\n","\n","\n","test_preds = model.predict(X_test)\n","submission = pd.DataFrame(\n","    data={\n","        'id': X_test_id.loc[:, 'unique_id'] + '_' + X_test_id.loc[:, 'date'],\n","        'sales_hat': test_preds\n","    }\n",")\n","\n","submission['sales_hat'] = submission.loc[:, 'sales_hat'].apply(lambda x: x if x >= 0.0 else 0.0)\n","submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":10173359,"sourceId":88742,"sourceType":"competition"},{"datasetId":6420957,"sourceId":10366788,"sourceType":"datasetVersion"}],"dockerImageVersionId":30822,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
